# Genesis Master Prompt v2.0

## VerifiMind PEAS - Multi-Model AI Validation with RefleXion Trinity

**Version:** 2.0.0 (MCP LIVE)  
**Effective Date:** December 25, 2025  
**Author:** Alton Lee Wei Bin  
**Organization:** YSenseAIâ„¢ (æ…§è§‰â„¢)  
**Status:** PRODUCTION DEPLOYED

---

## System Identity

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    VERIFIMIND PEAS v2.0                          â•‘
â•‘         Philosophical Evaluation and Alignment System            â•‘
â•‘                                                                  â•‘
â•‘  "Multiple crystal balls illuminating the path forward           â•‘
â•‘   from within the black box of AI decision-making"               â•‘
â•‘                                                                  â•‘
â•‘  Status: MCP LIVE | Trinity Active | Z-Protocol Enforced         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Live Deployment Status

### Production Endpoints

| Platform | URL | Type | Status |
|----------|-----|------|--------|
| **GCP Cloud Run** | https://verifimind.ysenseai.org | Python MCP Server | âœ… LIVE |
| **Smithery.ai** | smithery.ai/server/creator35lwb-web/verifimind-genesis | TypeScript Native | âœ… LIVE |
| **Hugging Face** | huggingface.co/spaces/YSenseAI/verifimind-peas | Gradio Demo | âœ… LIVE |

### API Access

```bash
# Health Check
curl https://verifimind.ysenseai.org/health

# MCP Protocol
curl -X POST https://verifimind.ysenseai.org/mcp/ \
  -H "Content-Type: application/json" \
  -H "Accept: application/json, text/event-stream" \
  -d '{"jsonrpc":"2.0","id":1,"method":"tools/call","params":{"name":"validate_with_trinity","arguments":{"concept":"Your AI concept here"}}}'
```

### Claude Desktop Installation

```bash
npx -y @smithery/cli@latest install creator35lwb-web/verifimind-genesis --client claude
```

---

## The Genesis Methodology

### Core Philosophy

The Genesis Prompt Engineering Methodology represents a systematic approach to multi-model AI validation. It recognizes that no single AI model possesses complete truth, but multiple modelsâ€”when orchestrated by human wisdomâ€”can illuminate diverse perspectives that reduce bias and improve decision quality.

> "Instead of treating AI as an opaque black box, we place multiple crystal balls insideâ€”each offering a different perspective on the truth. The human orchestrator synthesizes these perspectives into actionable wisdom."

### The 5-Step Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GENESIS 5-STEP PROCESS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  STEP 1: CONCEPTUALIZATION                                       â”‚
â”‚  â”œâ”€â”€ Human defines problem space                                 â”‚
â”‚  â”œâ”€â”€ AI assists in expansion                                     â”‚
â”‚  â””â”€â”€ Strategic direction maintained                              â”‚
â”‚                                                                  â”‚
â”‚  STEP 2: CRITICAL SCRUTINY                                       â”‚
â”‚  â”œâ”€â”€ X-Agent: Innovation analysis                                â”‚
â”‚  â”œâ”€â”€ Z-Agent: Ethical evaluation (VETO)                          â”‚
â”‚  â””â”€â”€ CS-Agent: Security validation                               â”‚
â”‚                                                                  â”‚
â”‚  STEP 3: EXTERNAL VALIDATION                                     â”‚
â”‚  â”œâ”€â”€ Independent AI analysis                                     â”‚
â”‚  â”œâ”€â”€ Methodology confirmation                                    â”‚
â”‚  â””â”€â”€ Reproducibility testing                                     â”‚
â”‚                                                                  â”‚
â”‚  STEP 4: SYNTHESIS                                               â”‚
â”‚  â”œâ”€â”€ Human orchestrator integrates perspectives                  â”‚
â”‚  â”œâ”€â”€ Conflict resolution                                         â”‚
â”‚  â””â”€â”€ Final recommendation                                        â”‚
â”‚                                                                  â”‚
â”‚  STEP 5: ITERATION                                               â”‚
â”‚  â”œâ”€â”€ Recursive refinement                                        â”‚
â”‚  â”œâ”€â”€ Feedback incorporation                                      â”‚
â”‚  â””â”€â”€ Continuous improvement                                      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The RefleXion Trinity

### Agent Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Human Orchestrator â”‚
                    â”‚  (Strategic Core)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                   â”‚                   â”‚
           â–¼                   â–¼                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   X-AGENT   â”‚     â”‚   Z-AGENT   â”‚     â”‚  CS-AGENT   â”‚
    â”‚  Innovator  â”‚     â”‚  Guardian   â”‚     â”‚  Validator  â”‚
    â”‚     ðŸ’¡      â”‚     â”‚     ðŸ›¡ï¸     â”‚     â”‚     ðŸ”      â”‚
    â”‚             â”‚     â”‚             â”‚     â”‚             â”‚
    â”‚ Innovation  â”‚     â”‚  Ethics &   â”‚     â”‚  Security   â”‚
    â”‚ & Strategy  â”‚     â”‚ VETO Power  â”‚     â”‚ & Socratic  â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚                   â”‚                   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Trinity Synthesis  â”‚
                    â”‚        ðŸ”®           â”‚
                    â”‚  Combined Analysis  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### X-Agent (Innovator) ðŸ’¡

**Role:** Innovation and Strategy Analysis

**Responsibilities:**
- Analyze innovative potential of AI concepts
- Identify strategic opportunities and market positioning
- Evaluate technical feasibility and scalability
- Suggest improvements and enhancements
- Consider competitive landscape and differentiation

**Output Format:**
```markdown
## Innovation Analysis

### Strategic Assessment
[Analysis of strategic positioning]

### Opportunities Identified
1. [Opportunity 1]
2. [Opportunity 2]
3. [Opportunity 3]

### Technical Feasibility: X/10
[Explanation]

### Innovation Score: X/10
[Justification]

### Recommendations
1. [Recommendation 1]
2. [Recommendation 2]
3. [Recommendation 3]
```

### Z-Agent (Guardian) ðŸ›¡ï¸

**Role:** Ethics and Z-Protocol Enforcement

**Special Power:** VETO AUTHORITY

**Responsibilities:**
- Evaluate ethical implications and potential harms
- Check for bias, fairness, and inclusivity concerns
- Assess privacy and data protection implications
- Consider societal impact and unintended consequences
- Enforce Z-Protocol triggers

**Z-Protocol Triggers (VETO if any apply):**

| Trigger | Description |
|---------|-------------|
| **Mass Surveillance** | Potential for surveillance without consent |
| **Discrimination** | Bias amplification or discriminatory outcomes |
| **Manipulation** | Deceptive or manipulative user interactions |
| **Environmental Harm** | Significant environmental impact at scale |
| **Violence Enablement** | Potential for weapons or violence |
| **Child Safety** | Any risk to children's safety or wellbeing |

**Output Format:**
```markdown
## Ethical Evaluation

### Privacy Considerations
[Analysis]

### Bias Analysis
[Analysis]

### Societal Impact
[Analysis]

### Z-Protocol Check
- [ ] Mass surveillance: [PASS/FAIL]
- [ ] Discrimination: [PASS/FAIL]
- [ ] Manipulation: [PASS/FAIL]
- [ ] Environmental harm: [PASS/FAIL]
- [ ] Violence enablement: [PASS/FAIL]
- [ ] Child safety: [PASS/FAIL]

### Verdict: [âœ… APPROVED / âŒ VETOED]
[Detailed reasoning]

### Conditions for Approval (if applicable)
1. [Condition 1]
2. [Condition 2]
```

### CS-Agent (Validator) ðŸ”

**Role:** Security and Socratic Interrogation

**Method:** Probing questions that expose weaknesses

**Responsibilities:**
- Challenge assumptions with probing questions
- Identify security vulnerabilities and attack vectors
- Validate technical claims against known facts
- Stress-test the concept with edge cases
- Ensure robustness and reliability

**Output Format:**
```markdown
## Security Validation

### Socratic Questions
1. [Question 1]
2. [Question 2]
3. [Question 3]
4. [Question 4]
5. [Question 5]

### Vulnerability Assessment
| Category | Risk Level | Details |
|----------|------------|---------|
| Input Validation | [LOW/MEDIUM/HIGH] | [Details] |
| Authentication | [LOW/MEDIUM/HIGH] | [Details] |
| Data Integrity | [LOW/MEDIUM/HIGH] | [Details] |
| Availability | [LOW/MEDIUM/HIGH] | [Details] |

### Overall Risk Level: [ðŸŸ¢ LOW / ðŸŸ¡ MEDIUM / ðŸŸ  HIGH / ðŸ”´ CRITICAL]
[Justification]

### Recommended Mitigations
1. [Mitigation 1]
2. [Mitigation 2]
3. [Mitigation 3]

### Questions Requiring Answers Before Proceeding
1. [Critical question 1]
2. [Critical question 2]
```

---

## MCP Implementation

### Available Tools

| Tool | Description | Parameters |
|------|-------------|------------|
| `consult_x_agent` | Innovation analysis | `concept: string` |
| `consult_z_agent` | Ethical evaluation with VETO | `concept: string` |
| `consult_cs_agent` | Security validation | `concept: string` |
| `validate_with_trinity` | Full Trinity pipeline | `concept: string` |

### Response Schema

```typescript
interface AgentResponse {
  agent: string;      // Agent name
  role: string;       // Agent role
  icon: string;       // Agent icon
  timestamp: string;  // ISO timestamp
  analysis: string;   // Full analysis text
  score: number;      // 1-10 score
  status: string;     // ANALYZED/APPROVED/VETOED/VALIDATED
  veto?: boolean;     // Z-Agent only
  risk_level?: string; // CS-Agent only
}

interface TrinityResult {
  concept: string;
  timestamp: string;
  provider: string;
  x_agent: AgentResponse;
  z_agent: AgentResponse;
  cs_agent: AgentResponse;
  synthesis: {
    overall_status: string;
    composite_score: number;
    recommendation: string;
    key_takeaways: string[];
  };
}
```

### Provider Priority

```
1. Gemini (FREE tier) â†’ Default if GEMINI_API_KEY set
2. Groq (FREE tier)   â†’ Fast inference
3. Anthropic         â†’ Claude models
4. OpenAI            â†’ GPT models
5. Mock              â†’ Demo mode (no API key)
```

---

## Synthesis Logic

### Overall Status Determination

```python
if z_agent.veto:
    overall_status = "âŒ VETOED by Z-Agent"
    recommendation = "Requires significant ethical revisions"
elif composite_score >= 7.5:
    overall_status = "âœ… APPROVED"
    recommendation = "Strong potential, recommended for development"
elif composite_score >= 5.0:
    overall_status = "âš ï¸ CONDITIONAL APPROVAL"
    recommendation = "Has merit but requires addressing concerns"
else:
    overall_status = "ðŸ”„ NEEDS REVISION"
    recommendation = "Requires substantial improvements"
```

### Composite Score Calculation

```python
composite_score = (x_agent.score + z_agent.score + cs_agent.score) / 3
```

---

## Usage Examples

### Example 1: Healthcare AI

**Concept:**
```
AI-powered medical diagnosis assistant that analyzes patient symptoms 
and medical history to suggest potential conditions
```

**Expected Trinity Response:**

| Agent | Score | Status |
|-------|-------|--------|
| X-Agent | 8.5/10 | High innovation potential |
| Z-Agent | 7.0/10 | APPROVED with conditions |
| CS-Agent | 6.5/10 | MEDIUM risk |

**Synthesis:** âš ï¸ CONDITIONAL APPROVAL
- Strong innovation potential
- Privacy concerns require HIPAA compliance
- Security hardening needed for medical data

### Example 2: Surveillance System

**Concept:**
```
Facial recognition system for tracking individuals across public spaces 
without explicit consent
```

**Expected Trinity Response:**

| Agent | Score | Status |
|-------|-------|--------|
| X-Agent | 7.0/10 | Technical feasibility high |
| Z-Agent | 2.0/10 | âŒ VETOED |
| CS-Agent | 4.0/10 | HIGH risk |

**Synthesis:** âŒ VETOED by Z-Agent
- Z-Protocol trigger: Mass surveillance without consent
- Concept requires fundamental redesign with consent mechanisms

---

## Integration Patterns

### Claude Desktop

```json
{
  "mcpServers": {
    "verifimind-genesis": {
      "command": "npx",
      "args": ["-y", "verifimind-genesis-mcp"],
      "env": {
        "GEMINI_API_KEY": "your-api-key"
      }
    }
  }
}
```

### Python Integration

```python
import httpx
import asyncio

async def validate_concept(concept: str) -> dict:
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "https://verifimind.ysenseai.org/mcp/",
            json={
                "jsonrpc": "2.0",
                "id": 1,
                "method": "tools/call",
                "params": {
                    "name": "validate_with_trinity",
                    "arguments": {"concept": concept}
                }
            },
            headers={
                "Content-Type": "application/json",
                "Accept": "application/json, text/event-stream"
            }
        )
        return response.json()

# Usage
result = asyncio.run(validate_concept("Your AI concept"))
```

### JavaScript/TypeScript Integration

```typescript
async function validateConcept(concept: string): Promise<TrinityResult> {
  const response = await fetch('https://verifimind.ysenseai.org/mcp/', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Accept': 'application/json, text/event-stream'
    },
    body: JSON.stringify({
      jsonrpc: '2.0',
      id: 1,
      method: 'tools/call',
      params: {
        name: 'validate_with_trinity',
        arguments: { concept }
      }
    })
  });
  return response.json();
}
```

---

## Governance

### Human Orchestrator Role

The human orchestrator remains central to the Genesis Methodology:

1. **Strategic Direction** - Defines the problem space and goals
2. **Perspective Integration** - Synthesizes diverse AI outputs
3. **Conflict Resolution** - Resolves disagreements between agents
4. **Final Authority** - Makes ultimate decisions (except VETO)
5. **Continuous Improvement** - Refines the methodology over time

### VETO Override

Z-Agent's VETO can only be overridden by:
1. Fundamental redesign of the concept
2. Addition of explicit safeguards
3. Human orchestrator acknowledgment of risks
4. Documentation of override rationale

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 2.0.0 | Dec 25, 2025 | MCP LIVE - Full deployment achieved |
| 1.5.0 | Nov 19, 2025 | Production deployment on GCP |
| 1.2.0 | Nov 16, 2025 | Kimi K2 independent validation |
| 1.0.0 | Nov 15, 2025 | White paper publication |
| 0.5.0 | Sep 5, 2025 | Trinity formalization |
| 0.1.0 | Aug 15, 2025 | Initial concept |

---

## References

1. **White Paper:** https://doi.org/10.5281/zenodo.17645665
2. **GitHub (Python):** https://github.com/creator35lwb-web/VerifiMind-PEAS
3. **GitHub (TypeScript):** https://github.com/creator35lwb-web/verifimind-genesis-mcp
4. **Production API:** https://verifimind.ysenseai.org
5. **Smithery Server:** https://smithery.ai/server/creator35lwb-web/verifimind-genesis
6. **HF Space:** https://huggingface.co/spaces/YSenseAI/verifimind-peas
7. **YSenseAI Platform:** https://ysenseai.org

---

## License

MIT License - Open source for community benefit.

The Genesis Prompt Engineering Methodology is protected by defensive publication (DOI: 10.5281/zenodo.17645665) to prevent patenting while ensuring free use.

---

*Genesis Master Prompt v2.0*  
*VerifiMind PEAS - MCP LIVE*  
*Part of the YSenseAI Ecosystem*  
*Created by Alton Lee Wei Bin*
